{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvi6cAEHY5sh"
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usUSep_lY7q8"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HP2ovD3xaDfC"
   },
   "outputs": [],
   "source": [
    "# Link to the API Key - https://beta.openai.com/docs/quickstart/add-your-api-key\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GPT_SECRET_KEY.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mGPT_SECRET_KEY.json\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/Documents/projetos/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GPT_SECRET_KEY.json'"
     ]
    }
   ],
   "source": [
    "with open('GPT_SECRET_KEY.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = data[\"API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    # system message first, it helps set the behavior of the assistant\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ: O atual Presidente do Brasil √© Jair Bolsonaro. Ele assumiu o cargo em 1¬∫ de janeiro de 2019, ap√≥s ganhar as elei√ß√µes presidenciais realizadas em outubro de 2018.\n",
      "ü§ñ: Eu sou uma intelig√™ncia artificial e meu \"nome\" √© OpenAI. Mas voc√™ pode me chamar de Assistente se quiser.\n",
      "ü§ñ: Para criar um programa de tarefas em Python, voc√™ pode seguir os seguintes passos:\n",
      "\n",
      "1. Importar a biblioteca datetime: `import datetime`\n",
      "\n",
      "2. Definir as tarefas que precisam ser executadas e o hor√°rio em que devem ser executadas (use um objeto datetime para definir a hora e a data): \n",
      "\n",
      "```\n",
      "tarefa_1 = {'descricao': 'Limpar a casa', 'horario': datetime(year=2022, month=6, day=13, hour=9, minute=0)}\n",
      "tarefa_2 = {'descricao': 'Fazer compras', 'horario': datetime(year=2022, month=6, day=14, hour=13, minute=30)}\n",
      "tarefa_3 = {'descricao': 'Estudar Python', 'horario': datetime(year=2022, month=6, day=15, hour=18, minute=0)}\n",
      "```\n",
      "\n",
      "3. Criar uma lista com todas as tarefas: `tarefas = [tarefa_1, tarefa_2, tarefa_3]`\n",
      "\n",
      "4. Definir uma fun√ß√£o que verifica se as tarefas foram conclu√≠das ou n√£o: \n",
      "\n",
      "```\n",
      "def verificar_tarefas():\n",
      "    agora = datetime.now()\n",
      "    for tarefa in tarefas:\n",
      "        if agora >= tarefa['horario']:\n",
      "            print(f\"A tarefa '{tarefa['descricao']}' deve ser executada agora.\")\n",
      "```\n",
      "\n",
      "5. Para executar o programa, basta chamar a fun√ß√£o `verificar_tarefas()`:\n",
      "\n",
      "```\n",
      "verificar_tarefas()\n",
      "```\n",
      "\n",
      "Dessa forma, a fun√ß√£o verifica se h√° alguma tarefa que precisa ser executada naquele momento e exibe uma mensagem informando qual tarefa deve ser executada. Voc√™ pode adicionar mais tarefas e modificar suas descri√ß√µes e hor√°rios conforme necess√°rio.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message = input(\"üë®‚Äçüíª: \")\n",
    "    if message:\n",
    "        messages.append(\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "        )\n",
    "        chat_completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\", messages=messages\n",
    "        )\n",
    "    \n",
    "    reply = chat_completion.choices[0].message.content\n",
    "    print(f\"ü§ñ: {reply}\")\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "14CPZJMxY_Ks",
    "aJaFmE9aZB_8"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
